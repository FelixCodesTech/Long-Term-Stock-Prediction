{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook is similar to the others (as of 5.2.2024)\n",
    "but it puts multiple stocks into the training data in form of rows, not columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelativeStockData(ticker, start, period, end=\"2024-2-2\", interval=\"1d\"):\n",
    "    if start == None:\n",
    "        data = yf.download(ticker, period=period, interval=interval)\n",
    "    else:\n",
    "        data = yf.download(ticker, start=start, end=end, interval=interval)\n",
    "\n",
    "    # Making it relative to the previous data point with 1% = 0.01\n",
    "    # All in a pandas dataframe\n",
    "\n",
    "    # Only use the close price\n",
    "    data = data[\"Close\"]\n",
    "    \n",
    "    data = data.pct_change().dropna()\n",
    "    data = data.reset_index()\n",
    "    data = data.rename(columns={\"index\": \"Date\"})\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def scrollData(data, contextWindow=10, solutionWindow=3):\n",
    "    # Scrolling through the data and returning the context window and the solution window\n",
    "    # Columns: Date, Solution1, Solution2, ..., Context0, Context-1, Context-2, ...\n",
    "\n",
    "    # Create the columns for the context and solution windows\n",
    "    for i in range(solutionWindow):\n",
    "        data[f\"Solution{i+1}\"] = data[\"Close\"].shift(-i)\n",
    "    for i in range(contextWindow):\n",
    "        data[f\"Context{-i}\"] = data[\"Close\"].shift(i)\n",
    "\n",
    "    # Drop the NaN values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Drop the Close column\n",
    "    data = data.drop(columns=[\"Close\"])\n",
    "\n",
    "    # Fix the index\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def unrelativizeDataArray(data):\n",
    "    # Unrelativize the data\n",
    "    # This is done by multiplying the previous data point with the current data point\n",
    "    # This is done for all values except the first\n",
    "\n",
    "    processedData = data.copy()\n",
    "\n",
    "    # Its an array in an array for some reason (with predictions)\n",
    "    if len(processedData) == 1:\n",
    "        processedData = processedData[0]\n",
    "\n",
    "    # Make the base (first value) 0\n",
    "    processedData[0] = 0\n",
    "\n",
    "    # Loop through the data and unrelativize it\n",
    "    for i in range(len(processedData)):\n",
    "        if i != 0:\n",
    "            processedData[i] = (processedData[i] + 1) * (processedData[i-1] + 1) - 1\n",
    "\n",
    "    return processedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Parameters\n",
    "contextWindow=1000\n",
    "solutionWindow=100\n",
    "\n",
    "stocksForData = [\"AAPL\", \"MSFT\", \"GOOGL\", \"FB\", \"AMZN\", \"IBM\", \"TSLA\", \"NFLX\", \n",
    "    \"NVDA\", \"INTC\", 'GOLLQ', 'GSK', 'NWG', 'BIRK', 'IHG', 'TAK', 'BAC', 'BK', 'CWK', 'CI', \n",
    "    'STT', 'JPM', 'WASH', 'CL', 'WLY', 'HIG', 'C', 'YORW', 'BMO', 'FISI', \n",
    "    'BG', 'EBC', 'RBGLY', 'MO', 'KEY', 'WTW', 'CFG', 'M', 'BNS', 'ROG', \n",
    "    'MCK', 'IFF', 'CHMG', 'NABZY', 'ONB', 'HIFS', 'TMP', 'PG', 'DE', \n",
    "    'BRK.B', 'PFS', 'ADX', 'DNB', 'RYI', 'SWK', 'TRC', 'PSO', 'BC', 'CHD', \n",
    "    'BHLB', 'SIEGY', 'FNF', 'AGR', 'CLF', 'PUK', 'UNM', 'LAZ', 'PFE', \n",
    "    'ESLOY', 'CMA', 'DCO', 'AXP', 'CCU', 'MATW', 'BHP', 'TRI', 'GLW', \n",
    "    'NYT', 'DOLE', 'AROW', 'CMTV', 'WFC', 'PNC', 'THG', 'SWBI', 'BHRB', \n",
    "    'TRV', 'OTIS', 'CNA', 'VIVHY', 'LEVI', 'BLCO', 'NVRI', 'WNEB', 'TD', \n",
    "    'CR', 'CXT', 'MGEE', 'MTB', 'SNN', 'NBTB', 'SAN', 'BBVA', 'SR', 'B', \n",
    "    'ACNB', 'ITOCY', 'MARUY', 'FITB', 'FHB']\n",
    "\n",
    "# Main Loop for getting more data in form of rows\n",
    "for stockTicker in stocksForData:\n",
    "    \n",
    "    # Get Data for AAPL\n",
    "    stockData = getRelativeStockData(stockTicker, start=None, period=\"max\", interval=\"1d\")\n",
    "\n",
    "    # Check if enough Data available\n",
    "    if len(stockData) < contextWindow + solutionWindow:\n",
    "        print(f\"Skipping {stockTicker} because there is not enough data\")\n",
    "        continue\n",
    "\n",
    "    # Scroll the data\n",
    "    stockData = scrollData(stockData, contextWindow=contextWindow, solutionWindow=solutionWindow)\n",
    "\n",
    "    # Add the data to the main data\n",
    "    if stockTicker == stocksForData[0]:\n",
    "        data = stockData\n",
    "    else:\n",
    "        data = pd.concat([data, stockData], ignore_index=True)\n",
    "\n",
    "\n",
    "    print(f\"Getting Data for {stockTicker}\")\n",
    "    print(f\"This one has {len(stockData)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing data\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "\n",
    "# Columns for the context and solution windows\n",
    "contextColumns = [f\"Context{-i}\" for i in range(contextWindow)]\n",
    "solutionColumns = [f\"Solution{i+1}\" for i in range(solutionWindow)]\n",
    "\n",
    "# Split X and y\n",
    "X_train = train[contextColumns]\n",
    "y_train = train[solutionColumns]\n",
    "\n",
    "X_test = test[contextColumns]\n",
    "y_test = test[solutionColumns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the MLP model\n",
    "model = MLPRegressor(hidden_layer_sizes=(100), max_iter=200, verbose=True, learning_rate='adaptive', learning_rate_init=0.0001, early_stopping=True)\n",
    "# model = MLPRegressor(hidden_layer_sizes=(100, 100, 100, 100, 100), activation='relu', solver='adam', alpha=0.0001, learning_rate='adaptive', learning_rate_init=0.001, verbose=True)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for AAPL\n",
    "stockData = getRelativeStockData(\"B\", start=None, period=\"5y\", interval=\"1d\")\n",
    "\n",
    "# Scroll the data\n",
    "stockData = scrollData(stockData, contextWindow=contextWindow, solutionWindow=solutionWindow)\n",
    "\n",
    "\n",
    "\n",
    "# Get the x'th data point for testing\n",
    "whereToPredict = 1 # points before end\n",
    "contextToPredict = stockData[contextColumns][-1-whereToPredict:-whereToPredict]\n",
    "solutionToPredict = stockData[solutionColumns][-1-whereToPredict:-whereToPredict]\n",
    "\n",
    "# Make Prediction on that data point\n",
    "predicitons = model.predict(contextToPredict)\n",
    "\n",
    "\n",
    "# Make the data usefull (reversing etc.)\n",
    "plottedContext = contextToPredict.values[0][::-1].reshape(-1, 1)\n",
    "plottedSolution = solutionToPredict.values.reshape(-1, 1)\n",
    "plottedPredictions = predicitons.reshape(-1, 1)\n",
    "\n",
    "# Plot the data in green, red, blue\n",
    "plt.plot(plottedContext, \"blue\")\n",
    "\n",
    "x_values = range(contextWindow - 1, contextWindow + len(plottedSolution) - 1)\n",
    "plt.plot(x_values, plottedSolution, \"green\")\n",
    "\n",
    "x_values = range(contextWindow, contextWindow + len(plottedPredictions))\n",
    "plt.plot(x_values, plottedPredictions, \"red\")\n",
    "\n",
    "# Set the x-axis range to zoom from ... to ...\n",
    "plt.xlim(len(unrelativizeDataArray(plottedContext))-len(unrelativizeDataArray(plottedPredictions))*1.1, len(unrelativizeDataArray(plottedContext)) + len(unrelativizeDataArray(plottedPredictions)) * 1.1)\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data in green, red, blue\n",
    "plt.plot(unrelativizeDataArray(plottedContext) - unrelativizeDataArray(plottedContext)[-1], \"blue\")\n",
    "\n",
    "x_values = range(contextWindow - 1, contextWindow + len(plottedSolution) - 1)\n",
    "y_values = unrelativizeDataArray(plottedSolution) * (unrelativizeDataArray(plottedContext)[-1] + 1)\n",
    "plt.plot(x_values, y_values , \"green\")\n",
    "\n",
    "x_values = range(contextWindow, contextWindow + len(plottedPredictions))\n",
    "y_values = unrelativizeDataArray(plottedPredictions) * (unrelativizeDataArray(plottedContext)[-1] + 1)\n",
    "plt.plot(x_values, y_values, \"red\")\n",
    "\n",
    "# Set the x-axis range to zoom from ... to ...\n",
    "xlim = len(unrelativizeDataArray(plottedContext))-len(unrelativizeDataArray(plottedPredictions))*1.1, len(unrelativizeDataArray(plottedContext)) + len(unrelativizeDataArray(plottedPredictions)) * 1.1\n",
    "plt.xlim(xlim)\n",
    "\n",
    "# Set the y-axis range to zoom from the minimum to the maximum of all values visible in the plot\n",
    "allValuesInPlot = np.append(unrelativizeDataArray(plottedPredictions), unrelativizeDataArray(plottedSolution))\n",
    "allValuesInPlot = np.append(allValuesInPlot, (unrelativizeDataArray(plottedContext) - unrelativizeDataArray(plottedContext)[-1])[int(xlim[0]):int(xlim[1])])\n",
    "\n",
    "# plt.ylim(min(allValuesInPlot)*1.1, max(allValuesInPlot)*1.1)\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating some fancy stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average percent error calculation\n",
    "# First we'll calculate the percentage error between all the predictions and the actual values\n",
    "# Then we'll calculate the average of those percentage errors\n",
    "\n",
    "# Average absolute error calculation\n",
    "# First we'll calculate the absolute error between all the predictions and the actual values\n",
    "# Then we'll calculate the average of those absolute errors\n",
    "\n",
    "avgPercentErrors = []\n",
    "avgAbsoluteErrors = []\n",
    "\n",
    "\n",
    "for i in range(len(plottedPredictions)):\n",
    "    percentError = abs((plottedPredictions[i] - plottedSolution[i]) / plottedSolution[i]) # 1% = 0.01\n",
    "    avgPercentErrors.append(percentError)\n",
    "\n",
    "    absoluteError = abs(plottedPredictions[i] - plottedSolution[i])\n",
    "    avgAbsoluteErrors.append(absoluteError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of the errors\n",
    "avgPercentError = (sum(avgPercentErrors) / len(avgPercentErrors))[0]\n",
    "avgAbsoluteError = (sum(avgAbsoluteErrors) / len(avgAbsoluteErrors))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum up with print statements\n",
    "print(f\"Average percent error: {round(avgPercentError*100, 2)}%\")\n",
    "print(f\"Average absolute error: {round(avgAbsoluteError*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some actually professional measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Testing Data\n",
    "predicitons = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, predicitons)\n",
    "\n",
    "# Print the mean squared error\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
